networks:
  app_network:
    driver: bridge
  monitoring_network:
    driver: bridge

services:
  flask-app-1:
    image: flask-app
    container_name: flask-app-1-v${APP_VERSION}
    networks:
      - app_network
      - monitoring_network
    environment:
      - APP_VERSION=${APP_VERSION}
      - MLFLOW_TRACKING_URI=file:///app/mlflow
      - MLFLOW_REQUEST_SAMPLING_RATE=0.001  # Sample 0.1% of requests
    volumes:
      - /var/lib/jenkins/workspace/mlip-model-train/mlflow-data:/app/mlflow  # Mount shared MLflow volume
      - /var/lib/jenkins/workspace/mlip-model-train/service/model:/app/service/model  # Mount model directory
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/health"]
      interval: 10s
      retries: 3
      start_period: 10s

  flask-app-2:
    image: flask-app
    container_name: flask-app-2-v${APP_VERSION}
    networks:
      - app_network
      - monitoring_network
    environment:
      - APP_VERSION=${APP_VERSION}
      - MLFLOW_TRACKING_URI=file:///app/mlflow
      - MLFLOW_REQUEST_SAMPLING_RATE=0.001  # Sample 0.1% of requests
    volumes:
      - /var/lib/jenkins/workspace/mlip-model-train/mlflow-data:/app/mlflow  # Mount shared MLflow volume
      - /var/lib/jenkins/workspace/mlip-model-train/service/model:/app/service/model  # Mount model directory
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/health"]
      interval: 10s
      retries: 3
      start_period: 10s

  load-balancer:
    image: nginx:latest
    container_name: load-balancer
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "8082:80"
    networks:
      - app_network
      - monitoring_network
    depends_on:
      - flask-app-1
      - flask-app-2
    restart: always

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    user: root
    volumes:
      - ./prometheus.yaml:/etc/prometheus/prometheus.yml
      - ./alert.rules.yaml:/etc/prometheus/alert.rules.yml
      - /var/run/docker.sock:/var/run/docker.sock 
    ports:
      - "9090:9090"
    networks:
      - monitoring_network
      - app_network
    restart: always

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    volumes:
      - grafana-storage:/var/lib/grafana
    ports:
      - "3000:3000"
    networks:
      - monitoring_network
      - app_network
    restart: always

  # Optional MLflow UI service - uncomment if you want a dedicated MLflow UI
  # mlflow-ui:
  #   image: python:3.9-slim
  #   container_name: mlflow-ui
  #   command: bash -c "pip install mlflow>=2.3.0 && mlflow ui --host 0.0.0.0 --port 5000"
  #   volumes:
  #     - mlflow-data:/mlflow
  #   environment:
  #     - MLFLOW_TRACKING_URI=file:///mlflow
  #   ports:
  #     - "5000:5000"
  #   networks:
  #     - app_network
  #   restart: always

volumes:
  grafana-storage:
  mlflow-data:  # New shared volume for MLflow data
